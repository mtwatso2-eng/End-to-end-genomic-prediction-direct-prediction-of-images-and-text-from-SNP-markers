{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOjqYElxBMZnIs0H0tDH0mX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":44,"metadata":{"id":"yJ2pBxHouvcn","executionInfo":{"status":"ok","timestamp":1752004741389,"user_tz":420,"elapsed":16,"user":{"displayName":"Mark Watson","userId":"11467267828871245451"}}},"outputs":[],"source":["# load and define globals\n","\n","import torch\n","from IPython.display import clear_output\n","import torchvision\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from PIL import Image, ImageDraw, ImageFont\n","import os\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","batch_size = 2**10 # 2**10\n","\n","image_size = (100, 100, 3) # 100, 100, 3\n","embedding_size = 16 # 64\n","\n","def to_img(x):\n","    return np.moveaxis(x.numpy() * 255, 0, -1).astype(np.uint8)\n","\n","# Hyperparameters\n","image_size = (100, 100, 3)  # Dimensions of input images (height, width, channels)\n","\n","class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","        self.fc1 = nn.Linear(np.prod(image_size), 400)  # Input layer to hidden layer\n","        self.fc21 = nn.Linear(400, embedding_size)  # Hidden layer to mean of latent space\n","        self.fc22 = nn.Linear(400, embedding_size)  # Hidden layer to log variance of latent space\n","        self.fc3 = nn.Linear(embedding_size, 400)  # Latent space to hidden layer\n","        self.fc4 = nn.Linear(400, np.prod(image_size))  # Hidden layer to output layer\n","\n","    # Encode function to obtain mean and log variance of the latent space\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    # Reparametrization trick to sample from the latent space\n","    def reparametrize(self, mu, logvar):\n","        std = logvar.mul(0.5).exp_()  # Compute standard deviation\n","        # Generate random noise\n","        if torch.cuda.is_available():\n","            eps = torch.cuda.FloatTensor(std.size()).normal_()\n","        else:\n","            eps = torch.FloatTensor(std.size()).normal_()\n","        eps = Variable(eps)\n","        return eps.mul(std).add_(mu)  # Return the sampled latent vector\n","\n","    # Decode function to reconstruct the image from the latent vector\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.sigmoid(self.fc4(h3))\n","\n","    # Forward pass through the VAE\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparametrize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","def take_mean(df, accessions):\n","    df = pd.DataFrame(df)\n","    df['Accession'] = accessions\n","    df_grouped = df.groupby('Accession').mean()  # Automatically handles NaN with .mean()\n","    return df_grouped.reset_index(drop=True) # Reset index and drop the Accession column"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","os.chdir('/content/drive/Shareddrives/Strawberries/Image experiment/')\n","\n","random_seed = 1\n","n_genotypes = 500"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhFgldLVv27D","executionInfo":{"status":"ok","timestamp":1752004746533,"user_tz":420,"elapsed":3469,"user":{"displayName":"Mark Watson","userId":"11467267828871245451"}},"outputId":"7db3f81f-c6ac-464a-cbba-528be256655b"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["model = VAE()\n","model.to(device)\n","model.load_state_dict(torch.load(str(random_seed) + \"_vae_\" + str(embedding_size) + \".pth\", map_location=torch.device('cpu')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-wDqbBGYzfJr","executionInfo":{"status":"ok","timestamp":1752004748270,"user_tz":420,"elapsed":1541,"user":{"displayName":"Mark Watson","userId":"11467267828871245451"}},"outputId":"4474d3a0-8be2-4548-c66f-1e060d48c58e"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["images = torch.load('fullImages.pt')\n","trainKey = np.genfromtxt(f\"{random_seed}_trainKey.csv\", delimiter=',', skip_header=0)\n","testKey = np.genfromtxt(f\"{random_seed}_testKey.csv\", delimiter=',', skip_header=0)\n","accessions = trainKey.copy()\n","accessions[testKey >= 0] = testKey[testKey >= 0]\n","embeddings = []\n","for i in images:\n","  image = i.view(1, -1).to(device)  # Ensure image is on GPU and properly reshaped\n","  mu, logvar = model.encode(image)\n","  encoded = model.reparametrize(mu, logvar)\n","  embeddings.append(encoded.cpu().detach().numpy())\n","embeddings = np.array(embeddings).squeeze()\n","mean_embeddings = np.array(take_mean(embeddings, accessions))\n","rrBLUPPredictedEmbeddings = torch.tensor(pd.read_csv(str(random_seed) + '_rrBLUPpredictedEmbeddings_' + str(embedding_size) + '.csv').to_numpy(), dtype = torch.float32)"],"metadata":{"id":"MjNY1E3C1Sa_","executionInfo":{"status":"ok","timestamp":1752004826147,"user_tz":420,"elapsed":77874,"user":{"displayName":"Mark Watson","userId":"11467267828871245451"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["sampledImages = []\n","mosaics = []\n","encodedDecodedImages = []\n","encodedDecodedMosaics = []\n","meanEncodedDecodedImages = []\n","endToEndImages = []\n","for i in range(len(rrBLUPPredictedEmbeddings))[0:n_genotypes]:\n","  theseImages = images[np.where(accessions == i)]\n","  sampledImages.append(to_img(theseImages[0]))\n","\n","  num_images = len(theseImages)\n","  num_cols = int(np.ceil(np.sqrt(num_images)))\n","  num_rows = num_cols\n","  mosaic = np.zeros((num_rows * image_size[0], num_cols * image_size[1], image_size[2]), dtype=np.uint8)\n","  for j in range(num_images):\n","    row = j // num_cols\n","    col = j % num_cols\n","    mosaic[row * image_size[0]:(row + 1) * image_size[0], col * image_size[1]:(col + 1) * image_size[1], :] = to_img(theseImages[j])\n","  mosaic = cv2.resize(mosaic, (1000, 1000))\n","  mosaics.append(mosaic)\n","\n","  theseEmbeddings = torch.tensor(embeddings[np.where(accessions == i)])\n","  encodedDecodedMosaic = np.zeros((num_rows * image_size[0], num_cols * image_size[1], image_size[2]), dtype=np.uint8)\n","  for j in range(num_images):\n","    row = j // num_cols\n","    col = j % num_cols\n","    decoded_image = model.decode(theseEmbeddings[j])\n","    decoded_image = decoded_image.view(1, -1)\n","    encodedDecodedMosaic[row * image_size[0]:(row + 1) * image_size[0], col * image_size[1]:(col + 1) * image_size[1], :] = to_img(decoded_image.detach().cpu().view(image_size[::-1]))\n","  encodedDecodedMosaic = cv2.resize(encodedDecodedMosaic, (1000, 1000))\n","  encodedDecodedMosaics.append(encodedDecodedMosaic)\n","\n","  decoded_image = model.decode(theseEmbeddings[0])\n","  decoded_image = decoded_image.view(1, -1)\n","  decoded_image = to_img(decoded_image.detach().cpu().view(image_size[::-1]))\n","  decoded_image = cv2.resize(decoded_image, (1000, 1000))\n","  encodedDecodedImages.append(decoded_image)\n","\n","  decoded_image = model.decode(torch.tensor(mean_embeddings[i]))\n","  decoded_image = decoded_image.view(1, -1)\n","  decoded_image = to_img(decoded_image.detach().cpu().view(image_size[::-1]))\n","  decoded_image = cv2.resize(decoded_image, (1000, 1000))\n","  meanEncodedDecodedImages.append(decoded_image)\n","\n","  rrBLUPPredictedEmbedding = rrBLUPPredictedEmbeddings[i,:]\n","  decoded_image = model.decode(rrBLUPPredictedEmbedding.to(device))\n","  decoded_image = decoded_image.view(1, -1)\n","  decoded_image = to_img(decoded_image.cpu().detach().view(image_size[::-1]))\n","  decoded_image = cv2.resize(decoded_image, (1000, 1000))\n","  endToEndImages.append(decoded_image)"],"metadata":{"id":"0D1xoqU9x7b_","executionInfo":{"status":"ok","timestamp":1752005568420,"user_tz":420,"elapsed":91006,"user":{"displayName":"Mark Watson","userId":"11467267828871245451"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["n_per_column_block = 6 # 50\n","\n","column_blocks = []\n","for column_block in np.split(np.array(range(n_genotypes)), (n_genotypes // n_per_column_block)):\n","  print(column_block)\n","  fourColumnMosaics = []\n","  labels = [\"Original\", \"Encoded-decoded\", \"Mean encoded-decoded\", \"End-to-end\"]\n","  white = (255, 255, 255)\n","\n","  # Load a TTF font\n","  font_path = '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'  # Change for your OS\n","  font = ImageFont.truetype(font_path, size=40)\n","\n","  for i in column_block:\n","      h, w, c = meanEncodedDecodedImages[i].shape\n","      row = np.zeros((h, 4 * w, c), dtype=np.uint8)\n","\n","      # Fill in the 4 columns\n","      row[:, 0*w:1*w, :] = mosaics[i][:,:,::-1]\n","      row[:, 1*w:2*w, :] = encodedDecodedMosaics[i][:,:,::-1]\n","      row[:, 2*w:3*w, :] = meanEncodedDecodedImages[i][:,:,::-1]\n","      row[:, 3*w:4*w, :] = endToEndImages[i][:,:,::-1]\n","\n","      # Add white vertical dividing lines between columns\n","      for j in range(1, 4):\n","          cv2.line(row, (j * w, 0), (j * w, h - 1), white, thickness=2)\n","\n","      # Convert to PIL for text drawing\n","      row_pil = Image.fromarray(row)\n","      draw = ImageDraw.Draw(row_pil)\n","\n","      # Draw the labels\n","      for j, label in enumerate(labels):\n","          text_pos = (j * w + 10, 10)  # y=10 is top of the image\n","          draw.text(text_pos, label, font=font, fill=white)\n","\n","      # Back to NumPy\n","      row = np.array(row_pil)\n","\n","      fourColumnMosaics.append(row)\n","\n","  # Stack rows into one big image\n","  full_mosaic = np.vstack(fourColumnMosaics)\n","\n","  # Add red horizontal lines between rows\n","  row_height = h\n","  for i in range(1, len(fourColumnMosaics)):\n","      y = i * row_height\n","      cv2.line(full_mosaic, (0, y), (full_mosaic.shape[1] - 1, y), white, thickness=2)\n","\n","  column_blocks.append(full_mosaic)\n","\n","  break\n","\n","# combine column blocks horizontally\n","full_mosaic = np.hstack(column_blocks)\n","# separate column blocks with vertical white lines\n","for i in range(1, len(column_blocks)):\n","  cv2.line(full_mosaic, (i * full_mosaic.shape[1] // len(column_blocks), 0), (i * full_mosaic.shape[1] // len(column_blocks), full_mosaic.shape[0] - 1), white, thickness=2)\n","\n","cv2.imwrite(\"figures/prediction_results_mosaic_temp.png\", full_mosaic[:,:,::-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0XN4-Ui_xszX","executionInfo":{"status":"ok","timestamp":1752005618015,"user_tz":420,"elapsed":1601,"user":{"displayName":"Mark Watson","userId":"11467267828871245451"}},"outputId":"fb750ad3-e89f-4ef7-a2ad-1c88bc88214f"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 3 4 5]\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":52}]}]}